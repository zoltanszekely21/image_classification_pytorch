{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"pytorch_image_classification.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNVvYY11v8W0COddn42EdVg"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"riN-6obuSufe"},"source":["from google.colab import drive \r\n","drive.mount ('/content/drive/')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Zn2mx_4YVaOl"},"source":["PROJECT_PATH= \"/content/drive/My Drive/aerialcactus//\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BL4780fNSsEs"},"source":["import pandas as pd \r\n","import matplotlib.pyplot as plt \r\n","import torch\r\n","import torch.nn.functional as F\r\n","import torchvision\r\n","import torchvision.transforms as transforms\r\n","\r\n","from torch.utils.data import Dataset, DataLoader\r\n","from sklearn.model_selection import train_test_split\r\n","\r\n","%matplotlib inline\r\n","\r\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jyW2sGtkHQVK"},"source":["import os\r\n","os.getcwd()\r\n","# place the files in your IDE working dicrectory .\r\n","labels = pd.read_csv(r'/content/drive/My Drive/aerialcactus/train.csv')\r\n","submission = pd.read_csv(r'/content/drive/My Drive/aerialcactus/sample_submission.csv')\r\n","\r\n","train_path = r'/content/drive/My Drive/aerialcactus/train/train/'\r\n","test_path = r'/content/drive/My Drive/aerialcactus/test/test/'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4ia3OefxH6ZR"},"source":["labels.head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4FTQYXq2H9lq"},"source":["labels.tail()\r\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5uvGQ8FWIAUf"},"source":["labels['has_cactus'].value_counts()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"B8zBaSDqIDfI"},"source":["label = 'Has Cactus', 'Hasn\\'t Cactus'\r\n","plt.figure(figsize = (8,8))\r\n","plt.pie(labels.groupby('has_cactus').size(), labels = label, autopct='%1.1f%%', shadow=True, startangle=90)\r\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"as6FF7V7Ip_F"},"source":["import matplotlib.image as img\r\n","fig,ax = plt.subplots(1,5,figsize = (15,3))\r\n","\r\n","for i,idx in enumerate(labels[labels['has_cactus'] == 1]['id'][-5:]):\r\n","    path = os.path.join(train_path,idx)\r\n","    ax[i].imshow(img.imread(path))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7tCOtZUOJLkX"},"source":["fig,ax = plt.subplots(1,5,figsize = (15,3))\r\n","for i,idx in enumerate(labels[labels['has_cactus'] == 0]['id'][:5]):\r\n","    path = os.path.join(train_path,idx)\r\n","    ax[i].imshow(img.imread(path))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yNbS0KooM1Bc"},"source":["import numpy as np\r\n","import matplotlib.pyplot as plt\r\n","\r\n","def imshow(image, ax=None, title=None, normalize=True):\r\n","    if ax is None:\r\n","        fig, ax = plt.subplots()\r\n","    image = image.numpy().transpose((1, 2, 0))\r\n","\r\n","    if normalize:\r\n","        mean = np.array([0.485, 0.456, 0.406])\r\n","        std = np.array([0.229, 0.224, 0.225])\r\n","        image = std * image + mean\r\n","        image = np.clip(image, 0, 1)\r\n","\r\n","    ax.imshow(image)\r\n","    ax.spines['top'].set_visible(False)\r\n","    ax.spines['right'].set_visible(False)\r\n","    ax.spines['left'].set_visible(False)\r\n","    ax.spines['bottom'].set_visible(False)\r\n","    ax.tick_params(axis='both', length=0)\r\n","    ax.set_xticklabels('')\r\n","    ax.set_yticklabels('')\r\n","\r\n","    return ax\r\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gCAP-zk6NKy3"},"source":["class CactiDataset(Dataset):\r\n","    def __init__(self, data, path , transform = None):\r\n","        super().__init__()\r\n","        self.data = data.values\r\n","        self.path = path\r\n","        self.transform = transform\r\n","        \r\n","    def __len__(self):\r\n","        return len(self.data)\r\n","    \r\n","    def __getitem__(self,index):\r\n","        img_name,label = self.data[index]\r\n","        img_path = os.path.join(self.path, img_name)\r\n","        image = img.imread(img_path)\r\n","        if self.transform is not None:\r\n","            image = self.transform(image)\r\n","        return image, label"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RBSItjcHNNrF"},"source":["train_transform = transforms.Compose([transforms.ToPILImage(),\r\n","                                      transforms.ToTensor(),\r\n","                                      transforms.Normalize(means,std)])\r\n","\r\n","test_transform = transforms.Compose([transforms.ToPILImage(),\r\n","                                     transforms.ToTensor(),\r\n","                                     transforms.Normalize(means,std)])\r\n","\r\n","valid_transform = transforms.Compose([transforms.ToPILImage(),\r\n","                                     transforms.ToTensor(),\r\n","                                     transforms.Normalize(means,std)])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WjDcm9hDPlWT"},"source":["train, valid_data = train_test_split(labels, stratify=labels.has_cactus, test_size=0.2)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DG9IA4QMPnG1"},"source":["train_data = CactiDataset(train, train_path, train_transform )\r\n","valid_data = CactiDataset(valid_data, train_path, valid_transform )\r\n","test_data = CactiDataset(submission, test_path, test_transform )"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eVv3lw_iPw9c"},"source":["# Hyper parameters\r\n","\r\n","num_epochs = 35\r\n","num_classes = 2\r\n","batch_size = 25\r\n","learning_rate = 0.001"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AYMgb9QqPy_W"},"source":["# CPU or GPU\r\n","\r\n","device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\r\n","device"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Py6Chn3hP1_r"},"source":["train_loader = DataLoader(dataset = train_data, batch_size = batch_size, shuffle=True, num_workers=0)\r\n","valid_loader = DataLoader(dataset = valid_data, batch_size = batch_size, shuffle=False, num_workers=0)\r\n","test_loader = DataLoader(dataset = test_data, batch_size = batch_size, shuffle=False, num_workers=0)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1eP3rBfZP52M"},"source":["import numpy as np\r\n","import matplotlib.pyplot as plt\r\n","\r\n","def imshow(image, ax=None, title=None, normalize=True):\r\n","    if ax is None:\r\n","        fig, ax = plt.subplots()\r\n","    image = image.numpy().transpose((1, 2, 0))\r\n","\r\n","    if normalize:\r\n","        mean = np.array([0.485, 0.456, 0.406])\r\n","        std = np.array([0.229, 0.224, 0.225])\r\n","        image = std * image + mean\r\n","        image = np.clip(image, 0, 1)\r\n","\r\n","    ax.imshow(image)\r\n","    ax.spines['top'].set_visible(False)\r\n","    ax.spines['right'].set_visible(False)\r\n","    ax.spines['left'].set_visible(False)\r\n","    ax.spines['bottom'].set_visible(False)\r\n","    ax.tick_params(axis='both', length=0)\r\n","    ax.set_xticklabels('')\r\n","    ax.set_yticklabels('')\r\n","\r\n","    return ax"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jaPh191lP9Cd"},"source":["trainimages, trainlabels = next(iter(train_loader))\r\n","\r\n","fig, axes = plt.subplots(figsize=(12, 12), ncols=5)\r\n","print('training images')\r\n","for i in range(5):\r\n","    axe1 = axes[i] \r\n","    imshow(trainimages[i], ax=axe1, normalize=False)\r\n","\r\n","print(trainimages[0].size())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1obvaizGQBjX"},"source":["epochs = 35\r\n","batch_size = 25\r\n","learning_rate = 0.001"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QogMH3yBQFJI"},"source":["import torch\r\n","import torch.nn as nn\r\n","import torch.nn.functional as F\r\n","\r\n","class CNN(nn.Module): \r\n","    def __init__(self):\r\n","        super(CNN, self).__init__()\r\n","        self.conv1 = nn.Conv2d(in_channels=3, out_channels=10, kernel_size=3)\r\n","        self.conv2 = nn.Conv2d(10, 20, kernel_size=3)\r\n","        self.conv2_drop = nn.Dropout2d()\r\n","        self.fc1 = nn.Linear(720, 1024)\r\n","        self.fc2 = nn.Linear(1024, 2)\r\n","\r\n","    def forward(self, x):\r\n","        x = F.relu(F.max_pool2d(self.conv1(x), 2))\r\n","        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\r\n","        x = x.view(x.shape[0],-1)\r\n","        x = F.relu(self.fc1(x))\r\n","        x = F.dropout(x, training=self.training)\r\n","        x = self.fc2(x)\r\n","        return x"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"T2-1eq15QGZy"},"source":["model = CNN()\r\n","print(model)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BFtxhY31QKR0"},"source":["model = CNN().to(device)\r\n","criterion = nn.CrossEntropyLoss()\r\n","optimizer = torch.optim.Adam(model.parameters(),lr = learning_rate)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MUeHN5UUQNM_"},"source":["%%time\r\n","# keeping-track-of-losses \r\n","train_losses = []\r\n","valid_losses = []\r\n","\r\n","for epoch in range(1, num_epochs + 1):\r\n","    # keep-track-of-training-and-validation-loss\r\n","    train_loss = 0.0\r\n","    valid_loss = 0.0\r\n","    \r\n","    # training-the-model\r\n","    model.train()\r\n","    for data, target in train_loader:\r\n","        # move-tensors-to-GPU \r\n","        data = data.to(device)\r\n","        target = target.to(device)\r\n","        \r\n","        # clear-the-gradients-of-all-optimized-variables\r\n","        optimizer.zero_grad()\r\n","        # forward-pass: compute-predicted-outputs-by-passing-inputs-to-the-model\r\n","        output = model(data)\r\n","        # calculate-the-batch-loss\r\n","        loss = criterion(output, target)\r\n","        # backward-pass: compute-gradient-of-the-loss-wrt-model-parameters\r\n","        loss.backward()\r\n","        # perform-a-ingle-optimization-step (parameter-update)\r\n","        optimizer.step()\r\n","        # update-training-loss\r\n","        train_loss += loss.item() * data.size(0)\r\n","        \r\n","    # validate-the-model\r\n","    model.eval()\r\n","    for data, target in valid_loader:\r\n","        \r\n","        data = data.to(device)\r\n","        target = target.to(device)\r\n","        \r\n","        output = model(data)\r\n","        \r\n","        loss = criterion(output, target)\r\n","        \r\n","        # update-average-validation-loss \r\n","        valid_loss += loss.item() * data.size(0)\r\n","    \r\n","    # calculate-average-losses\r\n","    train_loss = train_loss/len(train_loader.sampler)\r\n","    valid_loss = valid_loss/len(valid_loader.sampler)\r\n","    train_losses.append(train_loss)\r\n","    valid_losses.append(valid_loss)\r\n","        \r\n","    # print-training/validation-statistics \r\n","    print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\r\n","        epoch, train_loss, valid_loss))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"u39h5lQqQV5F"},"source":["# test-the-model\r\n","model.eval()  # it-disables-dropout\r\n","with torch.no_grad():\r\n","    correct = 0\r\n","    total = 0\r\n","    for images, labels in valid_loader:\r\n","        images = images.to(device)\r\n","        labels = labels.to(device)\r\n","        outputs = model(images)\r\n","        _, predicted = torch.max(outputs.data, 1)\r\n","        total += labels.size(0)\r\n","        correct += (predicted == labels).sum().item()\r\n","          \r\n","    print('Test Accuracy of the model: {} %'.format(100 * correct / total))\r\n","\r\n","# Save \r\n","torch.save(model.state_dict(), 'model.ckpt')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VPlJEJssQYeD"},"source":["%matplotlib inline\r\n","%config InlineBackend.figure_format = 'retina'\r\n","\r\n","plt.plot(train_losses, label='Training loss')\r\n","plt.plot(valid_losses, label='Validation loss')\r\n","plt.xlabel(\"Epochs\")\r\n","plt.ylabel(\"Loss\")\r\n","plt.legend(frameon=False)"],"execution_count":null,"outputs":[]}]}